{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, r2_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "train_features = pd.read_csv(\"train_features.csv\")\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "test_features = pd.read_csv(\"test_features.csv\")\n",
    "\n",
    "pid_lst = set(list(test_features.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.groupby('pid', group_keys = False).mean()\n",
    "test_features = test_features.groupby('pid', group_keys = False).mean()\n",
    "train_labels = train_labels.sort_values('pid')\n",
    "\n",
    "train_labels = train_labels.set_index('pid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Damja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:10:59] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:01] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:03] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:05] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:07] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:11:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "##BEST PARAMETERS\n",
    "# {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 125, 'nthread': 1, 'objective': 'binary:logistic', 'reg_lambda': 1.5, 'seed': 33, 'silent': 1, 'subsample': 0.8, 'alpha' : 12}\n",
    "# xgb_params = {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 125, 'nthread': 1, 'objective': 'binary:logistic', 'reg_lambda': 1.5, 'seed': 33, 'silent': 1, 'subsample': 0.8, 'alpha' : 12}\n",
    "\n",
    "results = []\n",
    "\n",
    "labels = [\"LABEL_BaseExcess\", \"LABEL_Fibrinogen\", \"LABEL_AST\", \n",
    "          \"LABEL_Alkalinephos\", \"LABEL_Bilirubin_total\", \"LABEL_Lactate\", \n",
    "          \"LABEL_TroponinI\", \"LABEL_SaO2\",  \"LABEL_Bilirubin_direct\", \"LABEL_EtCO2\"]\n",
    " \n",
    "for i in range(len(labels)):\n",
    "    mod = xgb.XGBClassifier()\n",
    "    mod.fit(train_features, train_labels.loc[:, labels].iloc[:,i])\n",
    "    y_pred = mod.predict_proba(test_features)\n",
    "    results.append(y_pred[:,1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.992289</td>\n",
       "      <td>0.168586</td>\n",
       "      <td>0.855396</td>\n",
       "      <td>0.759530</td>\n",
       "      <td>0.886765</td>\n",
       "      <td>0.330509</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.142081</td>\n",
       "      <td>0.054636</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053830</td>\n",
       "      <td>0.034151</td>\n",
       "      <td>0.454847</td>\n",
       "      <td>0.354147</td>\n",
       "      <td>0.424002</td>\n",
       "      <td>0.049693</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.040849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037889</td>\n",
       "      <td>0.057389</td>\n",
       "      <td>0.119253</td>\n",
       "      <td>0.119768</td>\n",
       "      <td>0.137706</td>\n",
       "      <td>0.052663</td>\n",
       "      <td>0.051922</td>\n",
       "      <td>0.030176</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.001938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.988467</td>\n",
       "      <td>0.984169</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>0.970338</td>\n",
       "      <td>0.966823</td>\n",
       "      <td>0.501926</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.786200</td>\n",
       "      <td>0.780134</td>\n",
       "      <td>0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056855</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.130194</td>\n",
       "      <td>0.080578</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.031172</td>\n",
       "      <td>0.025853</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>0.020784</td>\n",
       "      <td>0.035085</td>\n",
       "      <td>0.109951</td>\n",
       "      <td>0.099931</td>\n",
       "      <td>0.072070</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.023081</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>0.718012</td>\n",
       "      <td>0.024549</td>\n",
       "      <td>0.614295</td>\n",
       "      <td>0.389916</td>\n",
       "      <td>0.392129</td>\n",
       "      <td>0.352833</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.196376</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>0.932557</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.066884</td>\n",
       "      <td>0.106087</td>\n",
       "      <td>0.057220</td>\n",
       "      <td>0.145873</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.560915</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.236114</td>\n",
       "      <td>0.294968</td>\n",
       "      <td>0.070343</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>0.241650</td>\n",
       "      <td>0.030725</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.003068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>0.047161</td>\n",
       "      <td>0.109757</td>\n",
       "      <td>0.312621</td>\n",
       "      <td>0.326485</td>\n",
       "      <td>0.497912</td>\n",
       "      <td>0.067999</td>\n",
       "      <td>0.979385</td>\n",
       "      <td>0.031834</td>\n",
       "      <td>0.075219</td>\n",
       "      <td>0.003865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  LABEL_Alkalinephos  \\\n",
       "0              0.992289          0.168586   0.855396            0.759530   \n",
       "1              0.053830          0.034151   0.454847            0.354147   \n",
       "2              0.037889          0.057389   0.119253            0.119768   \n",
       "3              0.988467          0.984169   0.967692            0.970338   \n",
       "4              0.056855          0.004896   0.130194            0.080578   \n",
       "...                 ...               ...        ...                 ...   \n",
       "12659          0.020784          0.035085   0.109951            0.099931   \n",
       "12660          0.718012          0.024549   0.614295            0.389916   \n",
       "12661          0.932557          0.001531   0.066884            0.106087   \n",
       "12662          0.000937          0.001848   0.236114            0.294968   \n",
       "12663          0.047161          0.109757   0.312621            0.326485   \n",
       "\n",
       "       LABEL_Bilirubin_total  LABEL_Lactate  LABEL_TroponinI  LABEL_SaO2  \\\n",
       "0                   0.886765       0.330509         0.000088    0.142081   \n",
       "1                   0.424002       0.049693         0.055556    0.106257   \n",
       "2                   0.137706       0.052663         0.051922    0.030176   \n",
       "3                   0.966823       0.501926         0.001836    0.786200   \n",
       "4                   0.061907       0.031172         0.025853    0.025814   \n",
       "...                      ...            ...              ...         ...   \n",
       "12659               0.072070       0.070524         0.001691    0.023081   \n",
       "12660               0.392129       0.352833         0.003531    0.196376   \n",
       "12661               0.057220       0.145873         0.000568    0.560915   \n",
       "12662               0.070343       0.019834         0.241650    0.030725   \n",
       "12663               0.497912       0.067999         0.979385    0.031834   \n",
       "\n",
       "       LABEL_Bilirubin_direct  LABEL_EtCO2  \n",
       "0                    0.054636     0.000308  \n",
       "1                    0.009528     0.040849  \n",
       "2                    0.004817     0.001938  \n",
       "3                    0.780134     0.000361  \n",
       "4                    0.001265     0.000115  \n",
       "...                       ...          ...  \n",
       "12659                0.005224     0.000024  \n",
       "12660                0.001085     0.000451  \n",
       "12661                0.011087     0.000075  \n",
       "12662                0.007430     0.003068  \n",
       "12663                0.075219     0.003865  \n",
       "\n",
       "[12664 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.transpose()\n",
    "results_df.columns = labels\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Damja\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Damja\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:11:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#lets try xgboost again\n",
    "##BEST PARAMETERS\n",
    "# {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 125, 'nthread': 1, 'objective': 'binary:logistic', 'reg_lambda': 1.5, 'seed': 33, 'silent': 1, 'subsample': 0.8, 'alpha' : 12}\n",
    "# xgb_params = {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 8, 'min_child_weight': 11, 'missing': -999, 'n_estimators': 125, 'nthread': 1, 'objective': 'binary:logistic', 'reg_lambda': 1.5, 'seed': 33, 'silent': 1, 'subsample': 0.8, 'alpha' : 12}\n",
    "\n",
    "#colsample_bytree = 0.7, learning_rate = 0.05, max_depth = 30, in_child_weight = 11, n_estimators = 12, nthread = 1, objective = \"binary:logistic\", reg_lambda = 1.5, seed = 33, silent = 1, subsample = 0.8)\n",
    "#scale_pos_weight = XY, due to imbalancededness\n",
    "\n",
    "results = []\n",
    "labels = [\"LABEL_Sepsis\"]\n",
    "\n",
    "mod = xgb.XGBClassifier()\n",
    "mod.fit(train_features, train_labels.loc[:, labels])\n",
    "y_pred = mod.predict_proba(test_features)\n",
    "results.append(y_pred[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>0.009826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>0.000992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>0.031564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>0.011238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>0.059618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LABEL_Sepsis\n",
       "0          0.028821\n",
       "1          0.024111\n",
       "2          0.011090\n",
       "3          0.008528\n",
       "4          0.016754\n",
       "...             ...\n",
       "12659      0.009826\n",
       "12660      0.000992\n",
       "12661      0.031564\n",
       "12662      0.011238\n",
       "12663      0.059618\n",
       "\n",
       "[12664 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df2 = pd.DataFrame(results)\n",
    "results_df2 = results_df2.transpose()\n",
    "results_df2.columns = labels\n",
    "\n",
    "(results_df2 ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "mod = xgb.XGBRegressor()\n",
    "labels = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    mod = xgb.XGBRegressor()\n",
    "    mod.fit(train_features, train_labels.loc[:, labels].iloc[:,i])\n",
    "    y_pred = mod.predict(test_features)\n",
    "    results.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df3 = pd.DataFrame(results)\n",
    "results_df3 = results_df3.transpose()\n",
    "results_df3.columns = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_lst = pd.DataFrame(pid_lst)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992289</td>\n",
       "      <td>0.168586</td>\n",
       "      <td>0.855396</td>\n",
       "      <td>0.759530</td>\n",
       "      <td>0.886765</td>\n",
       "      <td>0.330509</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.142081</td>\n",
       "      <td>0.054636</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.028821</td>\n",
       "      <td>15.058461</td>\n",
       "      <td>87.189697</td>\n",
       "      <td>98.254822</td>\n",
       "      <td>81.866043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.053830</td>\n",
       "      <td>0.034151</td>\n",
       "      <td>0.454847</td>\n",
       "      <td>0.354147</td>\n",
       "      <td>0.424002</td>\n",
       "      <td>0.049693</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.106257</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.040849</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>17.443316</td>\n",
       "      <td>82.117645</td>\n",
       "      <td>96.654160</td>\n",
       "      <td>100.327919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.037889</td>\n",
       "      <td>0.057389</td>\n",
       "      <td>0.119253</td>\n",
       "      <td>0.119768</td>\n",
       "      <td>0.137706</td>\n",
       "      <td>0.052663</td>\n",
       "      <td>0.051922</td>\n",
       "      <td>0.030176</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>18.491133</td>\n",
       "      <td>71.692032</td>\n",
       "      <td>95.548073</td>\n",
       "      <td>69.732536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.988467</td>\n",
       "      <td>0.984169</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>0.970338</td>\n",
       "      <td>0.966823</td>\n",
       "      <td>0.501926</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.786200</td>\n",
       "      <td>0.780134</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.008528</td>\n",
       "      <td>16.586477</td>\n",
       "      <td>84.039352</td>\n",
       "      <td>97.696236</td>\n",
       "      <td>89.786736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.056855</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>0.130194</td>\n",
       "      <td>0.080578</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.031172</td>\n",
       "      <td>0.025853</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.016754</td>\n",
       "      <td>19.623606</td>\n",
       "      <td>90.662109</td>\n",
       "      <td>96.716347</td>\n",
       "      <td>91.523109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>31647.0</td>\n",
       "      <td>0.020784</td>\n",
       "      <td>0.035085</td>\n",
       "      <td>0.109951</td>\n",
       "      <td>0.099931</td>\n",
       "      <td>0.072070</td>\n",
       "      <td>0.070524</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>0.023081</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.009826</td>\n",
       "      <td>15.941040</td>\n",
       "      <td>68.953674</td>\n",
       "      <td>96.986725</td>\n",
       "      <td>69.888908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>31649.0</td>\n",
       "      <td>0.718012</td>\n",
       "      <td>0.024549</td>\n",
       "      <td>0.614295</td>\n",
       "      <td>0.389916</td>\n",
       "      <td>0.392129</td>\n",
       "      <td>0.352833</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.196376</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>15.210969</td>\n",
       "      <td>81.251015</td>\n",
       "      <td>98.018600</td>\n",
       "      <td>89.168579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>31651.0</td>\n",
       "      <td>0.932557</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.066884</td>\n",
       "      <td>0.106087</td>\n",
       "      <td>0.057220</td>\n",
       "      <td>0.145873</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.560915</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.031564</td>\n",
       "      <td>19.263367</td>\n",
       "      <td>76.438370</td>\n",
       "      <td>98.578186</td>\n",
       "      <td>92.176033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>31652.0</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.001848</td>\n",
       "      <td>0.236114</td>\n",
       "      <td>0.294968</td>\n",
       "      <td>0.070343</td>\n",
       "      <td>0.019834</td>\n",
       "      <td>0.241650</td>\n",
       "      <td>0.030725</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.011238</td>\n",
       "      <td>19.523912</td>\n",
       "      <td>95.555946</td>\n",
       "      <td>97.838211</td>\n",
       "      <td>113.859863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>31655.0</td>\n",
       "      <td>0.047161</td>\n",
       "      <td>0.109757</td>\n",
       "      <td>0.312621</td>\n",
       "      <td>0.326485</td>\n",
       "      <td>0.497912</td>\n",
       "      <td>0.067999</td>\n",
       "      <td>0.979385</td>\n",
       "      <td>0.031834</td>\n",
       "      <td>0.075219</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.059618</td>\n",
       "      <td>17.256781</td>\n",
       "      <td>86.190758</td>\n",
       "      <td>99.134972</td>\n",
       "      <td>98.179237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0.0          0.992289          0.168586   0.855396   \n",
       "1          3.0          0.053830          0.034151   0.454847   \n",
       "2          5.0          0.037889          0.057389   0.119253   \n",
       "3          7.0          0.988467          0.984169   0.967692   \n",
       "4          9.0          0.056855          0.004896   0.130194   \n",
       "...        ...               ...               ...        ...   \n",
       "12659  31647.0          0.020784          0.035085   0.109951   \n",
       "12660  31649.0          0.718012          0.024549   0.614295   \n",
       "12661  31651.0          0.932557          0.001531   0.066884   \n",
       "12662  31652.0          0.000937          0.001848   0.236114   \n",
       "12663  31655.0          0.047161          0.109757   0.312621   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                0.759530               0.886765       0.330509   \n",
       "1                0.354147               0.424002       0.049693   \n",
       "2                0.119768               0.137706       0.052663   \n",
       "3                0.970338               0.966823       0.501926   \n",
       "4                0.080578               0.061907       0.031172   \n",
       "...                   ...                    ...            ...   \n",
       "12659            0.099931               0.072070       0.070524   \n",
       "12660            0.389916               0.392129       0.352833   \n",
       "12661            0.106087               0.057220       0.145873   \n",
       "12662            0.294968               0.070343       0.019834   \n",
       "12663            0.326485               0.497912       0.067999   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0             0.000088    0.142081                0.054636     0.000308   \n",
       "1             0.055556    0.106257                0.009528     0.040849   \n",
       "2             0.051922    0.030176                0.004817     0.001938   \n",
       "3             0.001836    0.786200                0.780134     0.000361   \n",
       "4             0.025853    0.025814                0.001265     0.000115   \n",
       "...                ...         ...                     ...          ...   \n",
       "12659         0.001691    0.023081                0.005224     0.000024   \n",
       "12660         0.003531    0.196376                0.001085     0.000451   \n",
       "12661         0.000568    0.560915                0.011087     0.000075   \n",
       "12662         0.241650    0.030725                0.007430     0.003068   \n",
       "12663         0.979385    0.031834                0.075219     0.003865   \n",
       "\n",
       "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
       "0          0.028821    15.058461   87.189697   98.254822        81.866043  \n",
       "1          0.024111    17.443316   82.117645   96.654160       100.327919  \n",
       "2          0.011090    18.491133   71.692032   95.548073        69.732536  \n",
       "3          0.008528    16.586477   84.039352   97.696236        89.786736  \n",
       "4          0.016754    19.623606   90.662109   96.716347        91.523109  \n",
       "...             ...          ...         ...         ...              ...  \n",
       "12659      0.009826    15.941040   68.953674   96.986725        69.888908  \n",
       "12660      0.000992    15.210969   81.251015   98.018600        89.168579  \n",
       "12661      0.031564    19.263367   76.438370   98.578186        92.176033  \n",
       "12662      0.011238    19.523912   95.555946   97.838211       113.859863  \n",
       "12663      0.059618    17.256781   86.190758   99.134972        98.179237  \n",
       "\n",
       "[12664 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### USE PID LIST!\n",
    "\n",
    "labels_all = [\"pid\", \"LABEL_BaseExcess\", \"LABEL_Fibrinogen\",\n",
    "              \"LABEL_AST\", \"LABEL_Alkalinephos\", \"LABEL_Bilirubin_total\",\n",
    "              \"LABEL_Lactate\", \"LABEL_TroponinI\", \"LABEL_SaO2\", \n",
    "              \"LABEL_Bilirubin_direct\", \"LABEL_EtCO2\", \"LABEL_Sepsis\",\n",
    "             'LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "\n",
    "preds = pd.DataFrame(np.column_stack((pid_lst, results_df, results_df2, results_df3)))\n",
    "\n",
    "preds.columns = labels_all\n",
    "\n",
    "preds\n",
    "# same format as submit file\n",
    "#pd.read_csv(\"sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds is a pandas dataframe containing the result\n",
    "preds.to_csv('prediction.zip', index=False, float_format='%.3f', compression='zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
