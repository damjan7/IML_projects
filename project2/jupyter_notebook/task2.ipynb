{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "train_features = pd.read_csv(\"train_features.csv\")\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "test_features = pd.read_csv(\"test_features.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign labels for the 2 subtasks\n",
    "train_labels1 = train_labels.iloc[:, 0:11].copy()\n",
    "train_labels2 = train_labels.iloc[:, [0, 11]].copy()\n",
    "train_labels3 = train_labels.iloc[:, [0, 12, 13, 14, 15]].copy()\n",
    "\n",
    "train_labels1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need data for the first 12 hours of stay\n",
    "train_features = train_features.loc[train_features[\"Time\"]<=12]\n",
    "test_features = test_features.loc[test_features[\"Time\"]<=12]\n",
    "# need col names for each variable after Time\n",
    "col_names = train_features.columns.values.tolist()[2:]\n",
    "#to get only 1 row per pid, need to transform data from long to wide format\n",
    "train_features = train_features.pivot(index='pid', columns=\"Time\")\n",
    "test_features = test_features.pivot(index='pid', columns=\"Time\")\n",
    "# rename colnames, number each variable for the respective time point\n",
    "new_colnames = [string+str(i) for string in col_names for i in range(1, 13)]\n",
    "#train_features.columns = train_features.columns.droplevel()\n",
    "#train_features.columns = new_colnames\n",
    "#test_features.columns = test_features.columns.droplevel()\n",
    "#test_features.columns = new_colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_colnames = [string+str(i) for string in col_names for i in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features.columns = train_features.columns.droplevel()\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "The following maps and numbers show, that many values of the features are missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = train_features.isnull().sum().sum()\n",
    "total = train_features.size\n",
    "print(13*\"-\", \"train features\", 13*\"-\")\n",
    "print(train_features.shape[0], \"observations,\", train_features.shape[1], \"variables\")\n",
    "print(\"Nb. of values:  \", total)\n",
    "print(\"Nb. of NaN:     \", missing)\n",
    "print(\"Portion of NaN: \", round(missing/total, 4))\n",
    "\n",
    "#plot a missing value heatmap\n",
    "ax = plt.axes()\n",
    "sns.heatmap(train_features.isnull(), yticklabels = False, cbar = False, cmap = \"viridis\", ax = ax)\n",
    "ax.set_title('Heatmap of the NaN for train features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = train_labels.isnull().sum().sum()\n",
    "total = train_labels.size\n",
    "print(13*\"-\", \"train labels\", 13*\"-\")\n",
    "print(train_labels.shape[0], \"observations,\", train_labels.shape[1], \"variables\")\n",
    "print(\"Nb. of values:  \", total)\n",
    "print(\"Nb. of NaN:     \", missing)\n",
    "print(\"Portion of NaN: \", round(missing/total, 4))\n",
    "\n",
    "#plot a missing value heatmap\n",
    "ax = plt.axes()\n",
    "sns.heatmap(train_labels.isnull(), yticklabels = False, cbar = False, cmap = \"viridis\", ax = ax)\n",
    "ax.set_title('Heatmap of the NaN for train labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing = test_features.isnull().sum().sum()\n",
    "total = test_features.size\n",
    "print(13*\"-\", \"test features\", 13*\"-\")\n",
    "print(test_features.shape[0], \"observations,\", test_features.shape[1], \"variables\")\n",
    "print(\"Nb. of values:  \", total)\n",
    "print(\"Nb. of NaN:     \", missing)\n",
    "print(\"Portion of NaN: \", round(missing/total, 4))\n",
    "\n",
    "#plot a missing value heatmap\n",
    "ax = plt.axes()\n",
    "sns.heatmap(test_features.isnull(), yticklabels = False, cbar = False, cmap = \"viridis\", ax = ax)\n",
    "ax.set_title('Heatmap of the NaN for test features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train features\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp_train = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_train = imp_train.fit(train_features)\n",
    "# Impute our data, then train\n",
    "#col_names = train_features.columns.values.tolist()\n",
    "train_features = pd.DataFrame(imp_train.transform(train_features))\n",
    "\n",
    "# test features\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp_test = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_test = imp_test.fit(test_features)\n",
    "# Impute our data, then train\n",
    "#col_names = test_features.columns.values.tolist()\n",
    "test_features = pd.DataFrame(imp_test.transform(test_features))\n",
    "\n",
    "missing = train_labels.isnull().sum().sum()\n",
    "print(\"Nb. of NaN train features: \", train_features.isnull().sum().sum())\n",
    "print(\"Nb. of NaN test features:  \", test_features.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[\"pid\"].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features[\"pid\"].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "clf.fit(train_features, train_labels2[\"LABEL_Sepsis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_features.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
